## Bloat-Aware Design for Big Data Applications

### 简要总结

​	使用托管型语言的大数据处理系统在运行任务时会产生大量对象，我们把这种现象叫做memory bloat；此外，将托管型运行时环境的自动内存管理方案应用到大数据处理应用会导致其性能降级，并且无法扩展到更大规模的数据集上。针对该现象，作者为大数据处理应用提出了 bloat-aware 的设计方案，旨在提高内存的使用效率和大数据处理应用的可扩展性。顾名思义，bloat-aware指的就是重点关注 JVM 堆中过多的对象（memory bloat 现象），且致力于减少对象数量使其保持在一个可控的范围内，不随着输入数据规模的增大而显著增加。

### 背景

​	对于常规的 Java 应用程序而言，内存在通常境况下都能满足其使用需求。而在大数据处理环境下，内存资源常常无法满足应用的需求。例如，Giraph中 1GB 的输入数据就能消耗完 12 GB 大小的堆空间。从使用者的角度来看，这显然无法接受。作者认为，导致这一现象的主要原因在于面向对象思想会导致大量对象“**随意**”产生，而这一现象在大数据处理环境下被放大。因此，数据处理无法扩展到更大规模。更细致地说，大量对象的产生带来了大量对象头和引用，它们消耗了JVM堆空间，并给GC带来了巨大压力；此外，面向对象中存在大量 delegation（因为内存中的对象用于存储输入数据，从这个角度上看，面向对象思想产生的大量delegation属于无用对象），它们占据的内存空间甚至比数据本身占的内存空间还要大。

### 实现思路

​	考虑到在大多数大数据应用中，许多对象的生命周期十分相似，如果把这些对象放在一起，就能减少每个对象带来的额外内存开销。因此同时，GC在回收内存时也无需遍历每个对象判断其是否存活，而是遍历一个对象集合，判断集合中的对象是否存活即可。考虑到现有的大数据处理系统中对 control path 和 data path 有明显的区分，而data path的代码量占总代码较少，产生的对象却更多。因此，作者考虑在data path中整合生命周期相同的小对象将它们放在一个java memory page中，而堆空间里只存放用于访问 page 的“指针”（文中称为 accessor ）。因此，Java 堆空间的数量得以大大减少，代价则是用户需要在binary level对page中的对象进行操作。（实际情况是提供一系列api，隐藏底层的细节，上层用户直接调用该api访问page中的对象，但编程模型发生了更改，如果用户之前编写了代码则需要重写代码）

​	作者提供方法的核心在于减少 object 的数量，在面向对象思想中，任何事物都可以被封装成对象，而这在大数据场景下会给 JVM 堆空间带来大量内存开销。因此，作者将数据应该真正被存储起来的部分存放在 java memory page（以下简称page，java.nio.ByteBuffer）中，而堆空间中只存放用于访问 page 数据的“指针”。通过证明，堆空间中用于访问 page 数据的“指针”数量是有上限的，并且不会随着输入数据规模的增大而显著增加。于是，该方法真正减少了对象的数量，从而缓解了大数据处理应用的内存压力。

### 思考与启发

​	从实验结果上看，该方案在不显著增加开发人员负担的情况下减少了堆空间中的对象数量，并将其控制在一个具体的范围内，从而解决了内存膨胀问题。但是，该方案有一个致命缺陷，即需要用户利用数据处理系统提供的api重新编写代码；对于已经写好的代码，该方案无法将其转换为“能够减少堆空间对象数量”的版本。尽管如此，但在2013年，该方案仍然是一个创新性很强的方案，作者在future work中提到要在下个版本中做到自动化，即实现一套编译环境（[FACADE](./facade_con.md)），能够将用户在该方案提出之前写好的代码转化为能够优化大数据应用内存效率的字节码，最后执行以达到预定效果。通过阅读这篇文章，我的启发如下：

- 作者思考问题很直接，在发现了面向对象思想的缺陷导致大量无用对象产生后，通过减少堆空间中对象的方式优化了大数据处理应用的内存使用；这样能够带来的效果虽然很好，但也带来了大量开销。因此，我们可以换一下思考问题的方式。例如，为什么在常规的 Java应用中面向对象的思想表现较好，而在大数据环境下内存消耗显著增加呢？如果能细化原因，并在此基础上提出解决问题的方案，相应的工作量也会减少，同时问题也可以得到解决。因此，我们考虑专注于某个点，思考其原因，并以此延伸得到实用性更强的解决方案；
- 这篇文章和之后提到的 [FACADE](./facade_con.md) 都提到了 object-bound，即将对象的数量限制在一个范围内（理论上不可能超出这个范围）。当我们能够将对象数量控制在某个范围内时，内存的优化和内存的分配也会变得方便，这个观点可以借鉴和参考；
- 事实证明，不改变 JVM，不改变 Java compiler，不需要用户添加手动标注，这三个要求同时满足比较困难。于是我们从数据处理框架层下手，改变它使其与 JVM 的 GC 相匹配，通过它得到需要用户标注才能得到的信息。但单独改变数据处理框架层无法做到优化大数据处理应用的内存使用，除非新实现一套内存管理方案（类似于Deca），在GC执行前就已经分配和回收好了内存。总而言之，我们的目的是优化大数据处理应用的内存使用，而手段则是从数据处理框架层出发，得到几种特定的内存使用模式，用于高效地指导内存分配与回收。