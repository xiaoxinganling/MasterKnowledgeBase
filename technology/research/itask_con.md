## Interruptible Tasks: Treating Memory Pressure As Interrupts for Highly Scalable Data-Parallel Programs    

### 1. 简要总结

​	以“数据并行”的方式处理大规模数据集会产生巨大的内存压力（memory pressure，包括GC开销巨大、out-of-memory error等），作者提出将memory pressure视为一种中断信号，即出现内存紧张时，“中断”某些**优先级**较低的任务以缓解内存紧张；而当内存恢复至空闲状态时，将已中断的任务从中断状态恢复。

### 2. 背景介绍

​	尽管分布式系统（大数据处理系统）在架构层面已经提高了其可扩展性，但单个节点上的可扩展性还有待提高，具体表现为，单个节点上运行的应用在性能上无法随着输入数据规模的增加而扩展。产生这一问题的主要原因是托管型语言的使用使得内存的使用**增长迅速**并且变得**难以预测**。（GC的不确定性）而现有的技术（文章发布与2015年，参照2015年前的各种研究方案）要么是根据任务类型进行调参或者根据任务过去的执行记录预测未来内存变化趋势。前者无法提供一个自动的方案，需要经验丰富的开发人员对系统进行配置；而后者尽管是自动方案，但却经常无法准确地捕捉内存的变化趋势。受到处理器处理硬件中断的启发，作者提出“中断”和“memory pressure”的观念，具体来说，当系统检测到“memory pressure”时，它会将一些正在执行的任务“中断”，并回收他们占用的全部或部分内存；而当“memory pressure”消失时，这些被“中断”的任务则会重新被激活（从被中断的位置开始执行）。

### 3. 实现思路

​	前文已提及大致思路，具体实现细节包括在“memory pressure”出现时正确并高效地中断任务；在“memory pressure”消失时对未完成的任务进行恢复。这些内容的实现依赖于编程模型（programming model）和运行时系统（runtime system）的提出，前者为开发者提供任务中断的抽象（开发者继承一个抽象类实现相应方法即可完成任务中断和恢复等过程），后者则为任务中断提供运行时环境并对任务进行调度（决定哪些任务中断或恢复）。

​	在中断任务时，作者并非将该任务占据的所有内存全部回收。首先，任务的内存使用被分为几部分：输入数据、任务执行时自身创建的数据结构、输出数据等。对于这几部分对象，作者采取了不同处理方式：输入数据中已经处理完毕的和任务自身创建的数据结构可以直接被清理，而未被处理的输入数据则尽量保存在内存中。至于任务的输出数据，作者将其分为结果数据（可直接被下一个任务使用）和中间数据（需要等待所有的结果产生完毕才能供下个任务使用）。对于前者，我们可以将其直接作为下个任务的输入数据，而后者需要尽量保存在内存中使得所有的中间数据生成完毕。当“memory pressure”严重时，上述需要“尽量保存在内存中”的对象会被序列化写入磁盘，待“memory pressure”缓解时被读入内存。

**何时中断任务？**

​	内存紧张，并且任务都处于“安全状态”（任务不处于任务执行的中间过程）时。LUGC用于扫描堆空间，判断“memory pressure”是否产生，而任务是否到达安全状态需要结合任务的具体语义。

**怎样中断任务？**

​	主要包含两部分：中断哪些任务以及中断的具体执行，前者可通过为任务设置优先级，中断优先级较低的任务来实现；而后者需要结合具体任务进行考虑（判断哪些输入数据已经被处理、哪些输出数据已经产生）

**实现细节的简要介绍**

实现细节主要包含编程模型和运行时系统的构建，编程模型与不同的大数据处理系统密切相关，大体上包含三个内容：实现`DataPartition`封装输入输出、实现`Itask`处理任务的中断与恢复、使用一些胶水代码将`DataPartition`和`Itask`联系起来从而实现整个系统。文章实现了Hyracks和Hadoop的“可中断任务”的编程模型，这里就不详细阐述了，主要是定义很多抽象类，然后让已有的代码继承这些抽象类并实现特定的方法。（为了给编程人员提供api将现有大数据处理系统已有的代码转化为本文阐述的系统的代码）

运行时系统指的是“可中断”任务运行所需的环境，包括`partition manager`（序列化和反序列化数据分区，内存不足时，`partition manager`会序列化那些已中断任务仍存于内存中的对象，序列化后如果仍存在`memory pressure`则中断新的任务）、`scheduler`（决定哪些任务中断和恢复）、`monitor`(判断何时中断和恢复应用)。

### 思考与启发

​	这篇文章受CPU中断的启发，将大数据处理系统中的"memory pressure"也视为一种中断。当中断信号产生时，系统中断一部分任务从而提高其可扩展性（避免OOM的产生）和性能（减少GC的执行）。该方法十分巧妙，启发如下：

- 很容易联想到将该方法和其他大数据处理系统的内存优化手段进行比较。以Yak为例，本文提及的方法是在”memory pressure“产生时提出”中断“的应对手段，待”pressure“离开时再回复系统的正常运行；而Yak则是在”memory pressure“产生前采取一些手段避免其产生。从这一点看，Yak考虑问题更加深入，但Yak付出的代价也更大，实现的系统也更加底层。如何平衡好实现难度与可用性也是我们应当考虑的问题。

- 作者从StackOverFlow上发表的帖子总结出大数据处理系统面临的严峻问题和帖子下方给出回答的不足之处，全文都是对现有解决方案的不足之处做出一定改进（同时也增加了一些代价，但作者反复强调这些代价是微不足道的），这是一种新奇的思路，并且以此得到的问题在解决后同时具有一定的实用性。

- 本文提及Spark中Stage的使用在某种程度上缓解了Stage之间的contention，而Stage内部的contention仍然在发生，我们要解决的问题也正是**缓解task之间的contention**，至于缓解的粒度大小，如何操作需要一步步地探索。

  > While resource contention can be avoided between stages, memory problems can still occur inside each stage.

- 本文在实现其思想时很大程度利用了系统的原有特性，例如，实现一个抽象类，并使得现有的功能类继承该抽象类，从而实现自己想要的功能，这种方法的正确性和性能都有一定的保证。——非入侵式。我们在实现自己的系统时应当尽量保证和原有的系统高耦合，并且充分利用原有系统中已经实现的“轮子”提高性能。

- 本文用到了静态分析的手段生成`task graph`，这为后面一系列功能的实现奠定了基础。（这部分可以借鉴参考，因为是**静态分析**），而作者的future work也说明了要想实现“全自动”，即对用户完全透明，不需要其添加任何额外的代码，还是需要从`compiler`入手。（至少现在看来是这样，但不保证其他手段可以越过`compiler`）